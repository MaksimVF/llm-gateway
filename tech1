Создай REST API-сервис под названием `llm-gateway` на FastAPI. Он будет использоваться как шлюз (gateway) между клиентами и сервером инференса LLM (например, llama-cpp). Основные требования:

1. **Структура проекта:**

llm-gateway/
├── main.py                         ← запуск FastAPI-приложения  
├── gateway/
│   ├── __init__.py
│   ├── routes.py                   ← обработка маршрута POST /v1/completions
│   ├── auth.py                     ← проверка API-ключей из .env
│   └── client.py                   ← проксирование запросов к серверу LLM
├── .env                            ← переменные окружения: ALLOWED_API_KEYS, LLM_SERVER_URL
├── requirements.txt                ← зависимости
└── README.md                       ← краткое описание

2. **Технические детали:**
- Проверка API-ключа из заголовка `Authorization: Bearer <key>` в `auth.py`
- Поддержка нескольких ключей (разделённых запятой) в переменной `.env`: `ALLOWED_API_KEYS`
- Отправка JSON-запроса на сервер LLM по адресу из `LLM_SERVER_URL`
- Возврат ответа клиенту в формате JSON
- Обработка ошибок подключения и невалидных ключей

3. **Дополнительно:**
- В `main.py` приложение FastAPI подключает маршруты.
- Пример запроса с `curl` и описание в `README.md`.

Создай весь код и структуру файлов. Комментарии внутри кода — на русском языке.